{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands On #4 - Balancing Cart Pole w/Q-learning\n",
    "\n",
    "## Goal:\n",
    "* Introduce the CartPole Environment\n",
    "    * More complex, Continuous\n",
    "* Implement Q-Learning for digitized CartPole\n",
    "    * Later we will use function approx and remove the requirement for digitization\n",
    "\n",
    "## Steps:\n",
    "1. Get familiar with Cartpole environment\n",
    "    * np.linspace() and np.digitize() for state space aggregation\n",
    "2. Program Q Learning\n",
    "3. Track & Plot Metrics to solve Cart Pole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference : \n",
    "* Based on Udacity github https://github.com/udacity/deep-reinforcement-learning/tree/master/monte-carlo plus\n",
    "* My solution for the DQN https://github.com/xsankar/DQN_Navigation/blob/master/Navigation-v2.ipynb\n",
    "* Kaggle https://www.kaggle.com/sandovaledwin/q-learning-algorithm-for-solving-frozenlake-game/notebook\n",
    "* Phil Tabor's RL in Motion github https://github.com/philtabor/Reinforcement-Learning-In-Motion/tree/master/Unit-7-The-Cartpole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Install the required packages\n",
    "\n",
    "* No esoteric requirements\n",
    "* You can run them without docker\n",
    "* pip install -r requirements.txt\n",
    "* Requirements\n",
    " * python 3.6, pytorch, openAI gym, numpy, matplotlib\n",
    " * anaconda is easier but not needed\n",
    " * Miniconda works fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define imports\n",
    "\n",
    "python 3, numpy, matplotlib, torch, gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import gym\n",
    "import PIL # for in-line display of certain environments\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import namedtuple, deque, defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# torch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Global Constants and other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants Definitions\n",
    "BUFFER_SIZE = int(1e5)  # replay buffer size\n",
    "BATCH_SIZE = 64         # minibatch size\n",
    "GAMMA = 0.99            # discount factor\n",
    "TAU = 1e-3              # for soft update of target parameters\n",
    "LR = 5e-4               # learning rate \n",
    "UPDATE_EVERY = 4        # how often to update the network\n",
    "# Number of neurons in the layers of the Q Network\n",
    "FC1_UNITS = 16\n",
    "FC2_UNITS = 8\n",
    "FC3_UNITS = 4\n",
    "# Store models flag. Store during calibration runs and do not store during hyperparameter search\n",
    "STORE_MODELS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20943951023931956\n",
      "-0.20943951023931956\n"
     ]
    }
   ],
   "source": [
    "# Work area to quickly test utility functions\n",
    "import math\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "'''\n",
    "start_time = time.time()\n",
    "time.sleep(10)\n",
    "print('Elapsed : {}'.format(timedelta(seconds=time.time() - start_time)))\n",
    "'''\n",
    "print(math.radians(12))\n",
    "print(math.radians(-12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda3/lib/python3.7/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=1200x800 at 0x12274FB38>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym, PIL\n",
    "env = gym.make('CartPole-v0')\n",
    "array = env.reset()\n",
    "PIL.Image.fromarray(env.render(mode='rgb_array'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 Create instance & Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=1200x800 at 0x123AAF5F8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "array = env.reset()\n",
    "#env.render()\n",
    "PIL.Image.fromarray(env.render(mode='rgb_array'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Examine the State and Action Spaces\n",
    "\n",
    "* The state space is continuous, with an observation space of 4 \n",
    "    * {x,$\\dot{x}$,$\\theta$, theta_dot}\n",
    "        * Cart Position,  Cart Velocity, Pole Angle, Pole Velocity at tip\n",
    "        * The angle, probably, is in radians\n",
    "\n",
    "The action space, on the contrary is simple viz. 0 = Left, 1 = Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(4,)\n",
      "Discrete(2)\n",
      "[0, 1]\n",
      "[ 0 = Left, 1 = Right ]\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space)\n",
    "print(env.action_space)\n",
    "act_space = [i for i in range(0,env.action_space.n)]\n",
    "print(act_space)\n",
    "# env.unwrapped.get_action_meanings() # AttributeError: 'FrozenLakeEnv' object has no attribute 'get_action_meanings'\n",
    "print('[ 0 = Left, 1 = Right ]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_elapsed_seconds', '_elapsed_steps', '_episode_started_at', '_max_episode_seconds', '_max_episode_steps', '_past_limit', 'action_space', 'class_name', 'close', 'compute_reward', 'env', 'metadata', 'observation_space', 'render', 'reset', 'reward_range', 'seed', 'spec', 'step', 'unwrapped']\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_pole_geom', 'action_space', 'axle', 'carttrans', 'close', 'force_mag', 'gravity', 'kinematics_integrator', 'length', 'masscart', 'masspole', 'metadata', 'np_random', 'observation_space', 'polemass_length', 'poletrans', 'render', 'reset', 'reward_range', 'seed', 'spec', 'state', 'step', 'steps_beyond_done', 'tau', 'theta_threshold_radians', 'total_mass', 'track', 'unwrapped', 'viewer', 'x_threshold']\n",
      "States =  Box(4,)\n",
      "Actions =  Discrete(2)\n"
     ]
    }
   ],
   "source": [
    "print(dir(env))\n",
    "print(dir(env.unwrapped))\n",
    "print('States = ',env.unwrapped.observation_space)\n",
    "print('Actions = ',env.unwrapped.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_states = env.observation_space.shape[0]\n",
    "num_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Test the environment with Random Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ [ 0.03003913  0.04557193  0.03585064 -0.01279381] ] -> 0  : [ [ 0.03095057 -0.15004534  0.03559476  0.29098137] ] R= 1.0\n",
      "[ [ 0.03095057 -0.15004534  0.03559476  0.29098137] ] -> 1  : [ [0.02794966 0.04455147 0.04141439 0.0097337 ] ] R= 1.0\n",
      "[ [0.02794966 0.04455147 0.04141439 0.0097337 ] ] -> 1  : [ [ 0.02884069  0.23905576  0.04160906 -0.26960022] ] R= 1.0\n",
      "[ [ 0.02884069  0.23905576  0.04160906 -0.26960022] ] -> 0  : [ [0.0336218  0.04336549 0.03621706 0.03591066] ] R= 1.0\n",
      "[ [0.0336218  0.04336549 0.03621706 0.03591066] ] -> 1  : [ [ 0.03448911  0.23794987  0.03693527 -0.24512902] ] R= 1.0\n",
      "[ [ 0.03448911  0.23794987  0.03693527 -0.24512902] ] -> 1  : [ [ 0.03924811  0.43252535  0.03203269 -0.52593668] ] R= 1.0\n",
      "[ [ 0.03924811  0.43252535  0.03203269 -0.52593668] ] -> 1  : [ [ 0.04789862  0.62718225  0.02151396 -0.80835624] ] R= 1.0\n",
      "[ [ 0.04789862  0.62718225  0.02151396 -0.80835624] ] -> 1  : [ [ 0.06044226  0.82200287  0.00534683 -1.09419494] ] R= 1.0\n",
      "[ [ 0.06044226  0.82200287  0.00534683 -1.09419494] ] -> 1  : [ [ 0.07688232  1.01705398 -0.01653707 -1.38519546] ] R= 1.0\n",
      "[ [ 0.07688232  1.01705398 -0.01653707 -1.38519546] ] -> 1  : [ [ 0.0972234   1.21237819 -0.04424098 -1.68300339] ] R= 1.0\n",
      "[ [ 0.0972234   1.21237819 -0.04424098 -1.68300339] ] -> 1  : [ [ 0.12147096  1.40798358 -0.07790105 -1.98912699] ] R= 1.0\n",
      "[ [ 0.12147096  1.40798358 -0.07790105 -1.98912699] ] -> 0  : [ [ 0.14963064  1.21376    -0.11768358 -1.72155491] ] R= 1.0\n",
      "[ [ 0.14963064  1.21376    -0.11768358 -1.72155491] ] -> 0  : [ [ 0.17390584  1.02016605 -0.15211468 -1.4676917 ] ] R= 1.0\n",
      "[ [ 0.17390584  1.02016605 -0.15211468 -1.4676917 ] ] -> 1  : [ [ 0.19430916  1.21678726 -0.18146852 -1.80376735] ] R= 1.0\n",
      "[ [ 0.19430916  1.21678726 -0.18146852 -1.80376735] ] -> 0  : [ [ 0.2186449   1.02409744 -0.21754386 -1.57253805] ] R= 1.0\n",
      "Episode 1 finished after 15 steps with a Total Reward = 15\n",
      "[ [-0.02300422  0.01927211 -0.00399297 -0.0045521 ] ] -> 0  : [ [-0.02261878 -0.17579235 -0.00408401  0.28686833] ] R= 1.0\n",
      "[ [-0.02261878 -0.17579235 -0.00408401  0.28686833] ] -> 0  : [ [-0.02613463 -0.37085582  0.00165336  0.5782604 ] ] R= 1.0\n",
      "[ [-0.02613463 -0.37085582  0.00165336  0.5782604 ] ] -> 0  : [ [-0.03355174 -0.56600091  0.01321856  0.87146371] ] R= 1.0\n",
      "[ [-0.03355174 -0.56600091  0.01321856  0.87146371] ] -> 0  : [ [-0.04487176 -0.76130012  0.03064784  1.16827308] ] R= 1.0\n",
      "[ [-0.04487176 -0.76130012  0.03064784  1.16827308] ] -> 1  : [ [-0.06009776 -0.56659     0.0540133   0.88535412] ] R= 1.0\n",
      "[ [-0.06009776 -0.56659     0.0540133   0.88535412] ] -> 0  : [ [-0.07142956 -0.76240203  0.07172038  1.19451601] ] R= 1.0\n",
      "[ [-0.07142956 -0.76240203  0.07172038  1.19451601] ] -> 1  : [ [-0.0866776  -0.56827832  0.0956107   0.92514673] ] R= 1.0\n",
      "[ [-0.0866776  -0.56827832  0.0956107   0.92514673] ] -> 1  : [ [-0.09804317 -0.37456868  0.11411364  0.66397609] ] R= 1.0\n",
      "[ [-0.09804317 -0.37456868  0.11411364  0.66397609] ] -> 0  : [ [-0.10553454 -0.57107762  0.12739316  0.99029903] ] R= 1.0\n",
      "[ [-0.10553454 -0.57107762  0.12739316  0.99029903] ] -> 0  : [ [-0.1169561  -0.76765314  0.14719914  1.32012524] ] R= 1.0\n",
      "[ [-0.1169561  -0.76765314  0.14719914  1.32012524] ] -> 1  : [ [-0.13230916 -0.57466627  0.17360164  1.07689589] ] R= 1.0\n",
      "[ [-0.13230916 -0.57466627  0.17360164  1.07689589] ] -> 1  : [ [-0.14380249 -0.38220903  0.19513956  0.84333215] ] R= 1.0\n",
      "[ [-0.14380249 -0.38220903  0.19513956  0.84333215] ] -> 1  : [ [-0.15144667 -0.19020883  0.21200621  0.61780553] ] R= 1.0\n",
      "Episode 2 finished after 13 steps with a Total Reward = 13\n",
      "[ [ 0.00577214 -0.03391326  0.03417679  0.01931714] ] -> 1  : [ [ 0.00509387  0.16070231  0.03456313 -0.26238972] ] R= 1.0\n",
      "[ [ 0.00509387  0.16070231  0.03456313 -0.26238972] ] -> 0  : [ [ 0.00830792 -0.03489552  0.02931534  0.04099133] ] R= 1.0\n",
      "[ [ 0.00830792 -0.03489552  0.02931534  0.04099133] ] -> 1  : [ [ 0.00761001  0.15979405  0.03013517 -0.24230008] ] R= 1.0\n",
      "[ [ 0.00761001  0.15979405  0.03013517 -0.24230008] ] -> 0  : [ [ 0.01080589 -0.0357451   0.02528916  0.05973388] ] R= 1.0\n",
      "[ [ 0.01080589 -0.0357451   0.02528916  0.05973388] ] -> 1  : [ [ 0.01009099  0.1590053   0.02648384 -0.22486408] ] R= 1.0\n",
      "[ [ 0.01009099  0.1590053   0.02648384 -0.22486408] ] -> 0  : [ [ 0.0132711  -0.03648496  0.02198656  0.0760538 ] ] R= 1.0\n",
      "[ [ 0.0132711  -0.03648496  0.02198656  0.0760538 ] ] -> 1  : [ [ 0.0125414   0.15831501  0.02350764 -0.209612  ] ] R= 1.0\n",
      "[ [ 0.0125414   0.15831501  0.02350764 -0.209612  ] ] -> 1  : [ [ 0.0157077   0.35309309  0.0193154  -0.49478778] ] R= 1.0\n",
      "[ [ 0.0157077   0.35309309  0.0193154  -0.49478778] ] -> 0  : [ [ 0.02276956  0.15770414  0.00941964 -0.19608065] ] R= 1.0\n",
      "[ [ 0.02276956  0.15770414  0.00941964 -0.19608065] ] -> 1  : [ [ 0.02592364  0.35269009  0.00549803 -0.48577728] ] R= 1.0\n",
      "[ [ 0.02592364  0.35269009  0.00549803 -0.48577728] ] -> 1  : [ [ 0.03297744  0.54773403 -0.00421752 -0.77672235] ] R= 1.0\n",
      "[ [ 0.03297744  0.54773403 -0.00421752 -0.77672235] ] -> 0  : [ [ 0.04393212  0.35267034 -0.01975197 -0.48536936] ] R= 1.0\n",
      "[ [ 0.04393212  0.35267034 -0.01975197 -0.48536936] ] -> 0  : [ [ 0.05098553  0.1578326  -0.02945935 -0.19897647] ] R= 1.0\n",
      "[ [ 0.05098553  0.1578326  -0.02945935 -0.19897647] ] -> 1  : [ [ 0.05414218  0.35336325 -0.03343888 -0.50080497] ] R= 1.0\n",
      "[ [ 0.05414218  0.35336325 -0.03343888 -0.50080497] ] -> 0  : [ [ 0.06120945  0.15872824 -0.04345498 -0.21884487] ] R= 1.0\n",
      "[ [ 0.06120945  0.15872824 -0.04345498 -0.21884487] ] -> 1  : [ [ 0.06438401  0.35444356 -0.04783188 -0.52491246] ] R= 1.0\n",
      "[ [ 0.06438401  0.35444356 -0.04783188 -0.52491246] ] -> 1  : [ [ 0.07147288  0.55020485 -0.05833013 -0.83227575] ] R= 1.0\n",
      "[ [ 0.07147288  0.55020485 -0.05833013 -0.83227575] ] -> 1  : [ [ 0.08247698  0.74607334 -0.07497564 -1.14271814] ] R= 1.0\n",
      "[ [ 0.08247698  0.74607334 -0.07497564 -1.14271814] ] -> 1  : [ [ 0.09739845  0.94209062 -0.09783001 -1.45794024] ] R= 1.0\n",
      "[ [ 0.09739845  0.94209062 -0.09783001 -1.45794024] ] -> 1  : [ [ 0.11624026  1.13826717 -0.12698881 -1.77951419] ] R= 1.0\n",
      "[ [ 0.11624026  1.13826717 -0.12698881 -1.77951419] ] -> 0  : [ [ 0.1390056   0.94478272 -0.16257909 -1.52885893] ] R= 1.0\n",
      "[ [ 0.1390056   0.94478272 -0.16257909 -1.52885893] ] -> 1  : [ [ 0.15790126  1.14144929 -0.19315627 -1.86755662] ] R= 1.0\n",
      "[ [ 0.15790126  1.14144929 -0.19315627 -1.86755662] ] -> 0  : [ [ 0.18073024  0.94889507 -0.2305074  -1.6405321 ] ] R= 1.0\n",
      "Episode 3 finished after 23 steps with a Total Reward = 23\n"
     ]
    }
   ],
   "source": [
    "for i_episode in range(3):\n",
    "    state = env.reset()\n",
    "    tot_reward = 0\n",
    "    steps = 0\n",
    "    while True:\n",
    "        action = env.action_space.sample()\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        print('[',state,']','->', action,' : [',next_state,']', 'R=',reward)\n",
    "        # env.render()\n",
    "        tot_reward += reward\n",
    "        steps += 1\n",
    "        if done:\n",
    "            print('Episode {:d} finished after {:d} steps with a Total Reward = {:.0f}'.format(i_episode+1,steps, tot_reward))\n",
    "            break\n",
    "        else:\n",
    "            state = next_state\n",
    "# Pole angle +/-12 degrees, Cart Pos +/- 2.4 or 200 steps\n",
    "# Cart Pos, Velocity, Pole Angle, Velocity\n",
    "# 12 degrees = .2094 radians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q Learning\n",
    "### Let us implement the Basic Q-Learning Algorithm\n",
    "<img src='../Qlearning_Alg.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 : Define policies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\epsilon$-Greedy\n",
    "\n",
    "<img src=\"../e_greedy.png\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_e_greedy_action(env,Q,state,epsilon,nA):\n",
    "    action = np.random.choice(np.arange(nA), p=get_probs(Q[state], epsilon, nA)) if state in Q else env.action_space.sample()\n",
    "    return action\n",
    "\n",
    "def get_probs(Q_s, epsilon, nA):\n",
    "    \"\"\" obtains the action probabilities corresponding to epsilon-greedy policy \"\"\"\n",
    "    policy_s = np.ones(nA) * epsilon / nA\n",
    "    best_a = np.argmax(Q_s)\n",
    "    policy_s[best_a] = 1 - epsilon + (epsilon / nA)\n",
    "    return policy_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We need to convert the sontinuous state space to discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discretize the spaces\n",
    "poleThetaSpace = np.linspace(-0.20943951, 0.20943951, 10)\n",
    "poleThetaVelSpace = np.linspace(-4, 4, 10)\n",
    "cartPosSpace = np.linspace(-2.4, 2.4, 10)\n",
    "cartVelSpace = np.linspace(-4, 4, 10)\n",
    "\n",
    "def getState(observation):\n",
    "    cartX, cartXdot, cartTheta, cartThetadot = observation\n",
    "    cartX = int(np.digitize(cartX, cartPosSpace))\n",
    "    cartXdot = int(np.digitize(cartXdot, cartVelSpace))\n",
    "    cartTheta = int(np.digitize(cartTheta, poleThetaSpace))\n",
    "    cartThetadot = int(np.digitize(cartThetadot, poleThetaVelSpace))\n",
    "\n",
    "    return (cartX, cartXdot, cartTheta, cartThetadot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses global variavle env\n",
    "def q_learning(n_episodes=2000, max_t=1000, \n",
    "               epsilon_start=1.0, epsilon_min=0.01, epsilon_decay=0.9995, # 0.995 gets to min by 1000 episodes\n",
    "               alpha=0.01, gamma=1.0):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        epsilon_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        epsilon_end (float): minimum value of epsilon\n",
    "        epsilon_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "        alpha = step-size parameter\n",
    "        gamma = discount rate\n",
    "    \"\"\"\n",
    "    # initialize empty dictionary of arrays\n",
    "    Q = defaultdict(lambda: np.zeros(num_actions))\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    epsilon = epsilon_start            # initialize epsilon\n",
    "    has_seen_13 = False\n",
    "    max_score = 0\n",
    "    # loop over episodes\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        score = 0\n",
    "        max_steps = 0\n",
    "        # monitor progress\n",
    "        if i_episode % 100 == 0:\n",
    "            print(\"\\rEpisode {}/{}\".format(i_episode, n_episodes), end=\"\")\n",
    "            sys.stdout.flush()\n",
    "        \n",
    "        s_t = env.reset()\n",
    "        a_t = choose_e_greedy_action(env,Q,getState(s_t),epsilon,num_actions)\n",
    "        t = 0\n",
    "        while True:\n",
    "            s_t_d = getState(s_t)\n",
    "            # state, reward, done, info = env.step(action)\n",
    "            s_t_1, reward, done, prob = env.step(a_t)\n",
    "            # print(state,reward,done, prob)\n",
    "            s_t_1_d = getState(s_t_1) # Digitize state\n",
    "            a_t_1 = choose_e_greedy_action(env,Q,s_t_1_d,epsilon,num_actions)\n",
    "            best_a = np.argmax(Q[s_t_1_d])\n",
    "            Q[s_t_d][a_t] = Q[s_t_d][a_t] + alpha * (reward + gamma*(Q[s_t_1_d][best_a]) - Q[s_t_d][a_t])\n",
    "            a_t = a_t_1\n",
    "            s_t = s_t_1\n",
    "            score += reward\n",
    "            max_steps += 1\n",
    "            if done:\n",
    "                break\n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save most recent score\n",
    "        epsilon = max(epsilon*epsilon_decay, epsilon_min) # decrease epsilon\n",
    "        print('\\rEpisode : {}\\tAverage Score : {:5.2f}\\tMax_steps : {}\\teps : {:5.3f}\\tMax.Score : {:5.3f}'.\\\n",
    "              format(i_episode, np.mean(scores_window),max_steps,epsilon,max_score), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode : {}\\tAverage Score : {:5.2f}\\tMax_steps : {}\\teps : {:5.3f}\\tMax.Score : {:5.3f}'.\\\n",
    "                  format(i_episode, np.mean(scores_window),max_steps,epsilon,max_score))\n",
    "        if (np.mean(scores_window)>=195.0) and (not has_seen_13):\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:5.2f}'.\\\n",
    "                  format(i_episode-100, np.mean(scores_window)))\n",
    "            # torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
    "            has_seen_13 = True\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "    return scores, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode : 100\tAverage Score : 22.79\tMax_steps : 31\teps : 0.951\tMax.Score : 73.000\n",
      "Episode : 200\tAverage Score : 20.17\tMax_steps : 35\teps : 0.905\tMax.Score : 74.000\n",
      "Episode : 300\tAverage Score : 21.35\tMax_steps : 19\teps : 0.861\tMax.Score : 117.000\n",
      "Episode : 400\tAverage Score : 24.14\tMax_steps : 13\teps : 0.819\tMax.Score : 117.000\n",
      "Episode : 500\tAverage Score : 24.43\tMax_steps : 16\teps : 0.779\tMax.Score : 117.000\n",
      "Episode : 600\tAverage Score : 20.47\tMax_steps : 36\teps : 0.741\tMax.Score : 117.000\n",
      "Episode : 700\tAverage Score : 23.18\tMax_steps : 11\teps : 0.705\tMax.Score : 117.000\n",
      "Episode : 800\tAverage Score : 21.49\tMax_steps : 18\teps : 0.670\tMax.Score : 117.000\n",
      "Episode : 900\tAverage Score : 20.57\tMax_steps : 21\teps : 0.638\tMax.Score : 117.000\n",
      "Episode : 1000\tAverage Score : 22.20\tMax_steps : 19\teps : 0.606\tMax.Score : 117.000\n",
      "Episode : 1100\tAverage Score : 21.76\tMax_steps : 12\teps : 0.577\tMax.Score : 117.000\n",
      "Episode : 1200\tAverage Score : 18.48\tMax_steps : 15\teps : 0.549\tMax.Score : 117.000\n",
      "Episode : 1300\tAverage Score : 21.45\tMax_steps : 13\teps : 0.522\tMax.Score : 117.000\n",
      "Episode : 1400\tAverage Score : 21.43\tMax_steps : 17\teps : 0.496\tMax.Score : 117.000\n",
      "Episode : 1500\tAverage Score : 21.68\tMax_steps : 22\teps : 0.472\tMax.Score : 117.000\n",
      "Episode : 1600\tAverage Score : 22.17\tMax_steps : 19\teps : 0.449\tMax.Score : 117.000\n",
      "Episode : 1700\tAverage Score : 21.88\tMax_steps : 21\teps : 0.427\tMax.Score : 117.000\n",
      "Episode : 1800\tAverage Score : 20.65\tMax_steps : 27\teps : 0.406\tMax.Score : 117.000\n",
      "Episode : 1900\tAverage Score : 21.25\tMax_steps : 27\teps : 0.387\tMax.Score : 117.000\n",
      "Episode : 2000\tAverage Score : 20.60\tMax_steps : 18\teps : 0.368\tMax.Score : 117.000\n",
      "Episode : 2100\tAverage Score : 22.54\tMax_steps : 17\teps : 0.350\tMax.Score : 117.000\n",
      "Episode : 2200\tAverage Score : 21.75\tMax_steps : 22\teps : 0.333\tMax.Score : 117.000\n",
      "Episode : 2300\tAverage Score : 22.32\tMax_steps : 21\teps : 0.317\tMax.Score : 117.000\n",
      "Episode : 2400\tAverage Score : 21.76\tMax_steps : 15\teps : 0.301\tMax.Score : 117.000\n",
      "Episode : 2500\tAverage Score : 20.63\tMax_steps : 13\teps : 0.286\tMax.Score : 117.000\n",
      "Episode : 2600\tAverage Score : 21.65\tMax_steps : 22\teps : 0.272\tMax.Score : 117.000\n",
      "Episode : 2700\tAverage Score : 21.90\tMax_steps : 16\teps : 0.259\tMax.Score : 117.000\n",
      "Episode : 2800\tAverage Score : 20.67\tMax_steps : 16\teps : 0.247\tMax.Score : 117.000\n",
      "Episode : 2900\tAverage Score : 20.21\tMax_steps : 17\teps : 0.234\tMax.Score : 117.000\n",
      "Episode : 3000\tAverage Score : 21.25\tMax_steps : 23\teps : 0.223\tMax.Score : 117.000\n",
      "Episode : 3100\tAverage Score : 20.65\tMax_steps : 29\teps : 0.212\tMax.Score : 117.000\n",
      "Episode : 3200\tAverage Score : 20.66\tMax_steps : 23\teps : 0.202\tMax.Score : 117.000\n",
      "Episode : 3300\tAverage Score : 21.02\tMax_steps : 24\teps : 0.192\tMax.Score : 117.000\n",
      "Episode : 3400\tAverage Score : 20.04\tMax_steps : 14\teps : 0.183\tMax.Score : 117.000\n",
      "Episode : 3500\tAverage Score : 22.81\tMax_steps : 19\teps : 0.174\tMax.Score : 117.000\n",
      "Episode : 3600\tAverage Score : 22.27\tMax_steps : 30\teps : 0.165\tMax.Score : 117.000\n",
      "Episode : 3700\tAverage Score : 21.06\tMax_steps : 23\teps : 0.157\tMax.Score : 117.000\n",
      "Episode : 3800\tAverage Score : 20.76\tMax_steps : 15\teps : 0.149\tMax.Score : 117.000\n",
      "Episode : 3900\tAverage Score : 21.16\tMax_steps : 21\teps : 0.142\tMax.Score : 117.000\n",
      "Episode : 4000\tAverage Score : 20.15\tMax_steps : 25\teps : 0.135\tMax.Score : 117.000\n",
      "Episode : 4100\tAverage Score : 20.63\tMax_steps : 22\teps : 0.129\tMax.Score : 117.000\n",
      "Episode : 4200\tAverage Score : 21.37\tMax_steps : 26\teps : 0.122\tMax.Score : 117.000\n",
      "Episode : 4300\tAverage Score : 19.98\tMax_steps : 22\teps : 0.116\tMax.Score : 117.000\n",
      "Episode : 4400\tAverage Score : 21.05\tMax_steps : 17\teps : 0.111\tMax.Score : 117.000\n",
      "Episode : 4500\tAverage Score : 20.80\tMax_steps : 22\teps : 0.105\tMax.Score : 117.000\n",
      "Episode : 4600\tAverage Score : 21.79\tMax_steps : 15\teps : 0.100\tMax.Score : 117.000\n",
      "Episode : 4700\tAverage Score : 21.37\tMax_steps : 19\teps : 0.095\tMax.Score : 117.000\n",
      "Episode : 4800\tAverage Score : 20.49\tMax_steps : 20\teps : 0.091\tMax.Score : 117.000\n",
      "Episode : 4900\tAverage Score : 20.90\tMax_steps : 26\teps : 0.086\tMax.Score : 117.000\n",
      "Episode : 5000\tAverage Score : 20.45\tMax_steps : 17\teps : 0.082\tMax.Score : 117.000\n",
      "Elapsed : 0:00:22.246744\n",
      "2019-01-18 09:06:07.485713\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Score 117.000000 at 200\n",
      "Percentile [25,50,75] : [17. 20. 24.]\n",
      "Variance : 56.910\n"
     ]
    }
   ],
   "source": [
    "# obtain the estimated optimal policy and corresponding action-value function\n",
    "start_time = time.time()\n",
    "scores, QVal = q_learning(n_episodes=5000)\n",
    "# env.close() # Close the environment\n",
    "print('Elapsed : {}'.format(timedelta(seconds=time.time() - start_time)))\n",
    "print(datetime.now())\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()\n",
    "print('Max Score {:2f} at {}'.format(np.max(scores), np.argmax(scores)))\n",
    "print('Percentile [25,50,75] : {}'.format(np.percentile(scores,[25,50,75])))\n",
    "print('Variance : {:.3f}'.format(np.var(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=(5, 5, 4, 5),v=[19.17831868 19.31179005]\n",
      "k=(5, 5, 4, 4),v=[19.09837663 15.47219135]\n",
      "k=(5, 6, 4, 4),v=[16.82113858  8.21437063]\n",
      "k=(5, 6, 3, 4),v=[12.6006042   5.79043561]\n",
      "k=(5, 6, 2, 4),v=[7.50676828 2.96703888]\n",
      "k=(5, 6, 1, 3),v=[1.47956603 1.28123685]\n",
      "k=(5, 6, 1, 4),v=[3.05887672 1.39329071]\n",
      "k=(5, 5, 0, 4),v=[0. 0.]\n",
      "k=(5, 5, 3, 4),v=[13.5009834  11.94645292]\n",
      "k=(5, 6, 2, 3),v=[2.89577126 1.54320223]\n",
      "k=(5, 7, 1, 2),v=[0.04591848 0.10466175]\n",
      "k=(5, 6, 0, 3),v=[0. 0.]\n",
      "k=(5, 5, 5, 5),v=[22.4684351 23.8007867]\n",
      "k=(5, 5, 5, 6),v=[1.99030761 9.23793045]\n",
      "k=(5, 5, 6, 5),v=[14.4943168 13.0224933]\n",
      "k=(5, 5, 5, 4),v=[22.84605791 13.94084217]\n",
      "k=(5, 6, 5, 4),v=[14.92754467  5.17928944]\n",
      "k=(5, 6, 0, 4),v=[0. 0.]\n",
      "k=(5, 4, 6, 6),v=[2.51809554 7.24679783]\n",
      "k=(5, 4, 7, 6),v=[2.44533962 7.11788918]\n",
      "k=(5, 5, 7, 6),v=[6.13450224 9.50061377]\n",
      "k=(5, 5, 7, 5),v=[9.9610447  8.08395086]\n",
      "k=(5, 5, 8, 6),v=[5.66225698 5.07492385]\n",
      "k=(5, 4, 9, 6),v=[1.94397155 1.39705843]\n",
      "k=(5, 5, 9, 6),v=[2.22631723 3.17554748]\n",
      "k=(5, 5, 10, 6),v=[0. 0.]\n",
      "k=(5, 5, 6, 6),v=[ 6.06819255 14.09684949]\n",
      "k=(5, 4, 8, 7),v=[0.6482919  1.48261053]\n",
      "k=(5, 4, 9, 7),v=[1.18581335 1.04312938]\n",
      "k=(5, 4, 10, 7),v=[0. 0.]\n",
      "k=(5, 5, 3, 5),v=[13.93514788 14.14078045]\n",
      "k=(5, 5, 1, 4),v=[4.38508174 3.96944922]\n",
      "k=(5, 5, 6, 4),v=[5.76353196 1.03217396]\n",
      "k=(5, 6, 6, 4),v=[1.50356017 0.59288529]\n",
      "k=(5, 6, 5, 3),v=[0.15444703 0.10302725]\n",
      "k=(5, 7, 4, 3),v=[0.11827751 0.0507307 ]\n",
      "k=(5, 7, 3, 2),v=[0.01 0.  ]\n",
      "k=(5, 7, 2, 3),v=[0.18570076 0.02068221]\n",
      "k=(5, 6, 4, 3),v=[1.26730922 0.41947549]\n",
      "k=(5, 6, 3, 3),v=[2.32969934 0.82393108]\n",
      "k=(5, 7, 0, 2),v=[0. 0.]\n",
      "k=(5, 4, 5, 6),v=[1.18515088 3.56361536]\n",
      "k=(5, 4, 8, 6),v=[1.90817604 4.61698654]\n",
      "k=(5, 4, 10, 6),v=[0. 0.]\n",
      "k=(5, 5, 4, 6),v=[0.98806469 7.45217346]\n",
      "k=(5, 4, 7, 7),v=[0.37179317 0.73818331]\n",
      "k=(5, 5, 8, 5),v=[6.27413283 3.45988355]\n",
      "k=(5, 5, 2, 5),v=[9.3909602  9.80077054]\n",
      "k=(5, 5, 2, 4),v=[9.3594945  8.65143359]\n",
      "k=(5, 3, 9, 8),v=[0.04900995 0.029701  ]\n",
      "k=(5, 3, 10, 8),v=[0. 0.]\n",
      "k=(5, 4, 3, 6),v=[0.38656928 1.77486796]\n",
      "k=(5, 4, 4, 6),v=[0.86976313 2.60627134]\n",
      "k=(5, 4, 5, 5),v=[0.11678897 0.90195031]\n",
      "k=(5, 3, 9, 7),v=[0.07725531 0.03303501]\n",
      "k=(4, 4, 9, 7),v=[0.01 0.01]\n",
      "k=(4, 3, 10, 7),v=[0. 0.]\n",
      "k=(5, 5, 9, 5),v=[1.52584541 2.78056434]\n",
      "k=(5, 5, 10, 7),v=[0. 0.]\n",
      "k=(5, 4, 10, 8),v=[0. 0.]\n",
      "k=(5, 4, 6, 7),v=[0.14425945 0.2138585 ]\n",
      "k=(5, 7, 1, 3),v=[0.03940399 0.10466175]\n",
      "k=(5, 6, 7, 4),v=[1.22980778 0.43771953]\n",
      "k=(5, 6, 6, 5),v=[2.20831386 0.32328171]\n",
      "k=(5, 3, 5, 7),v=[0.03990789 0.02020196]\n",
      "k=(5, 3, 6, 7),v=[0.         0.04097925]\n",
      "k=(5, 3, 7, 7),v=[0.06934355 0.0452179 ]\n",
      "k=(5, 3, 8, 7),v=[0.02069846 0.07012923]\n",
      "k=(4, 3, 9, 7),v=[0.01     0.029701]\n",
      "k=(4, 4, 10, 7),v=[0. 0.]\n",
      "k=(5, 7, 0, 3),v=[0. 0.]\n",
      "k=(5, 4, 2, 5),v=[0.137227   1.46071466]\n",
      "k=(5, 4, 2, 6),v=[0.48834121 0.14406105]\n",
      "k=(5, 4, 3, 5),v=[0.24445551 2.05996044]\n",
      "k=(5, 4, 1, 5),v=[0.27733526 2.69057719]\n",
      "k=(5, 3, 2, 6),v=[0.01 0.  ]\n",
      "k=(5, 3, 3, 6),v=[0.02 0.01]\n",
      "k=(4, 3, 4, 6),v=[0.02009701 0.029701  ]\n",
      "k=(4, 4, 4, 6),v=[0.         0.03127564]\n",
      "k=(4, 4, 5, 5),v=[0.05990732 0.14658468]\n",
      "k=(4, 4, 5, 6),v=[0.01       0.03109142]\n",
      "k=(4, 3, 5, 6),v=[0.0397 0.01  ]\n",
      "k=(4, 3, 6, 6),v=[0.   0.01]\n",
      "k=(4, 4, 6, 6),v=[0.01040881 0.07016462]\n",
      "k=(4, 4, 7, 5),v=[0.020001   0.03262293]\n",
      "k=(4, 4, 7, 6),v=[0.05950894 0.02021664]\n",
      "k=(4, 3, 7, 6),v=[0.01 0.  ]\n",
      "k=(4, 3, 8, 7),v=[0.01     0.020198]\n",
      "k=(6, 6, 0, 4),v=[0. 0.]\n",
      "k=(6, 6, 1, 4),v=[0.04018035 0.12524203]\n",
      "k=(6, 6, 0, 3),v=[0. 0.]\n",
      "k=(5, 7, 3, 3),v=[0.10735578 0.04975577]\n",
      "k=(4, 4, 9, 6),v=[0.02077835 0.0969571 ]\n",
      "k=(4, 4, 10, 6),v=[0. 0.]\n",
      "k=(5, 6, 8, 5),v=[3.19940818 0.67896391]\n",
      "k=(5, 6, 8, 4),v=[0.37161923 0.99046824]\n",
      "k=(5, 6, 7, 5),v=[0.17013157 0.92471129]\n",
      "k=(5, 5, 9, 7),v=[0.01       0.14259382]\n",
      "k=(5, 5, 10, 5),v=[0. 0.]\n",
      "k=(6, 7, 0, 2),v=[0. 0.]\n",
      "k=(5, 6, 9, 5),v=[1.37239682 3.07528844]\n",
      "k=(5, 6, 9, 4),v=[2.74903541 0.47298584]\n",
      "k=(5, 7, 8, 4),v=[0.48382742 0.07885783]\n",
      "k=(5, 7, 7, 4),v=[0.05634123 0.3125047 ]\n",
      "k=(5, 7, 6, 4),v=[0.05086415 0.14062699]\n",
      "k=(6, 7, 6, 4),v=[0.         0.07902272]\n",
      "k=(6, 7, 5, 3),v=[0.01069902 0.07875309]\n",
      "k=(6, 7, 4, 3),v=[0.11914445 0.05053305]\n",
      "k=(6, 8, 4, 3),v=[0.06463873 0.01      ]\n",
      "k=(6, 8, 3, 2),v=[0.   0.01]\n",
      "k=(6, 8, 2, 2),v=[0.   0.01]\n",
      "k=(6, 8, 1, 2),v=[0.0199 0.    ]\n",
      "k=(6, 8, 0, 2),v=[0. 0.]\n",
      "k=(5, 6, 5, 5),v=[0.91165481 0.18724322]\n",
      "k=(6, 6, 4, 5),v=[0.03970889 0.01      ]\n",
      "k=(6, 5, 4, 5),v=[0.03960497 0.019999  ]\n",
      "k=(6, 5, 4, 6),v=[0.     0.0102]\n",
      "k=(6, 5, 5, 6),v=[0.020299   0.04013149]\n",
      "k=(6, 5, 5, 5),v=[0.020099 0.01    ]\n",
      "k=(6, 5, 6, 6),v=[0.0203     0.11380088]\n",
      "k=(6, 5, 6, 5),v=[0.         0.02039599]\n",
      "k=(6, 5, 7, 5),v=[0.03990397 0.03039303]\n",
      "k=(6, 6, 7, 5),v=[0.39265808 0.10979489]\n",
      "k=(6, 5, 7, 6),v=[0.05069862 0.25126852]\n",
      "k=(6, 5, 8, 6),v=[0.20427117 0.07289415]\n",
      "k=(6, 5, 9, 6),v=[0.02019701 0.1589428 ]\n",
      "k=(6, 5, 10, 6),v=[0. 0.]\n",
      "k=(5, 5, 1, 5),v=[4.61832056 4.83212   ]\n",
      "k=(5, 5, 0, 5),v=[0. 0.]\n",
      "k=(5, 3, 8, 8),v=[0.010199 0.0101  ]\n",
      "k=(5, 3, 10, 7),v=[0. 0.]\n",
      "k=(5, 4, 5, 7),v=[0.02131295 0.10509588]\n",
      "k=(5, 7, 5, 3),v=[0.20754331 0.03096245]\n",
      "k=(6, 7, 2, 3),v=[0.07157881 0.23088269]\n",
      "k=(6, 7, 1, 3),v=[0.21816814 0.04910895]\n",
      "k=(5, 7, 2, 2),v=[0.0212519 0.0315323]\n",
      "k=(5, 5, 1, 3),v=[0.0407091  0.18359919]\n",
      "k=(5, 4, 6, 5),v=[0.11269781 0.16210476]\n",
      "k=(5, 5, 7, 4),v=[0.01296983 0.04080708]\n",
      "k=(4, 4, 8, 7),v=[0.01     0.020198]\n",
      "k=(5, 6, 9, 6),v=[0.0862846  0.16245958]\n",
      "k=(6, 6, 2, 4),v=[0.04028713 0.0901553 ]\n",
      "k=(6, 5, 2, 5),v=[0.     0.0101]\n",
      "k=(6, 5, 1, 5),v=[0.01 0.01]\n",
      "k=(6, 5, 1, 4),v=[0.     0.0101]\n",
      "k=(6, 5, 0, 4),v=[0. 0.]\n",
      "k=(4, 4, 8, 6),v=[0.02077834 0.05019301]\n",
      "k=(4, 5, 8, 5),v=[0.03019902 0.01      ]\n",
      "k=(4, 5, 9, 6),v=[0.04048623 0.04028709]\n",
      "k=(4, 5, 9, 5),v=[0.07911492 0.04078606]\n",
      "k=(4, 4, 6, 5),v=[0.04981573 0.06911198]\n",
      "k=(4, 5, 6, 5),v=[0.020693 0.020001]\n",
      "k=(4, 5, 6, 4),v=[0.03000101 0.010101  ]\n",
      "k=(4, 5, 5, 5),v=[0.07105312 0.        ]\n",
      "k=(3, 4, 7, 5),v=[0.01     0.020001]\n",
      "k=(3, 4, 7, 6),v=[0.     0.0101]\n",
      "k=(3, 5, 7, 5),v=[0.0101     0.02979999]\n",
      "k=(3, 5, 7, 4),v=[0.0102 0.01  ]\n",
      "k=(3, 5, 6, 4),v=[0.01     0.019999]\n",
      "k=(3, 5, 6, 5),v=[0.     0.0101]\n",
      "k=(3, 6, 5, 4),v=[0.   0.01]\n",
      "k=(3, 6, 5, 3),v=[0.01 0.  ]\n",
      "k=(3, 6, 4, 4),v=[0.   0.01]\n",
      "k=(3, 6, 4, 3),v=[0.   0.01]\n",
      "k=(4, 6, 3, 3),v=[0.01 0.  ]\n",
      "k=(4, 6, 2, 3),v=[0.     0.0199]\n",
      "k=(4, 6, 1, 3),v=[0.     0.0199]\n",
      "k=(4, 7, 0, 2),v=[0. 0.]\n",
      "k=(5, 4, 4, 5),v=[0.19927692 1.6914325 ]\n",
      "k=(5, 3, 5, 6),v=[0.         0.01734534]\n",
      "k=(5, 3, 6, 6),v=[0.0204003 0.       ]\n",
      "k=(6, 6, 8, 6),v=[0.19100672 0.04392353]\n",
      "k=(6, 6, 9, 6),v=[0.08193867 0.25125229]\n",
      "k=(6, 6, 10, 6),v=[0. 0.]\n",
      "k=(5, 4, 1, 6),v=[0.08675026 0.01052853]\n",
      "k=(5, 7, 7, 3),v=[0.04727259 0.17602919]\n",
      "k=(5, 7, 6, 3),v=[0.22372453 0.03163142]\n",
      "k=(5, 6, 6, 3),v=[0.         0.03086267]\n",
      "k=(5, 7, 9, 5),v=[0.0452668 0.       ]\n",
      "k=(6, 6, 9, 5),v=[0.06341684 0.019999  ]\n",
      "k=(6, 7, 9, 5),v=[0.03009403 0.0199    ]\n",
      "k=(6, 7, 9, 4),v=[0.03724594 0.        ]\n",
      "k=(6, 6, 10, 7),v=[0. 0.]\n",
      "k=(5, 4, 0, 4),v=[0. 0.]\n",
      "k=(5, 4, 7, 5),v=[0.02439831 0.04446527]\n",
      "k=(4, 5, 7, 5),v=[0.11694875 0.0701029 ]\n",
      "k=(4, 5, 7, 4),v=[0.03233275 0.        ]\n",
      "k=(4, 5, 7, 6),v=[0.         0.03118896]\n",
      "k=(4, 5, 8, 6),v=[0.         0.03010098]\n",
      "k=(4, 5, 10, 6),v=[0. 0.]\n",
      "k=(5, 3, 2, 7),v=[0.         0.03692097]\n",
      "k=(4, 4, 3, 6),v=[0.010199 0.      ]\n",
      "k=(4, 3, 5, 7),v=[0.0199 0.    ]\n",
      "k=(4, 2, 6, 7),v=[0.01 0.  ]\n",
      "k=(4, 2, 7, 8),v=[0.01 0.  ]\n",
      "k=(4, 2, 8, 8),v=[0.010199 0.02    ]\n",
      "k=(4, 2, 9, 8),v=[0.029701 0.      ]\n",
      "k=(4, 2, 10, 8),v=[0. 0.]\n",
      "k=(5, 6, 10, 5),v=[0. 0.]\n",
      "k=(5, 5, 2, 3),v=[0.05901014 0.        ]\n",
      "k=(5, 6, 0, 2),v=[0. 0.]\n",
      "k=(5, 7, 9, 4),v=[0.19196018 0.01071728]\n",
      "k=(6, 6, 8, 5),v=[0.09307184 0.40969936]\n",
      "k=(6, 6, 10, 5),v=[0. 0.]\n",
      "k=(6, 7, 8, 4),v=[0.02455038 0.10108859]\n",
      "k=(6, 7, 7, 4),v=[0.14143872 0.01059803]\n",
      "k=(6, 6, 7, 6),v=[0.33546509 0.0489409 ]\n",
      "k=(6, 5, 8, 7),v=[0.0808016  0.03225475]\n",
      "k=(6, 5, 9, 7),v=[0.15214668 0.0199    ]\n",
      "k=(6, 5, 10, 8),v=[0. 0.]\n",
      "k=(6, 6, 1, 3),v=[0.01       0.03940399]\n",
      "k=(5, 6, 4, 5),v=[0.05730706 0.07315714]\n",
      "k=(6, 6, 4, 4),v=[0.04029811 0.        ]\n",
      "k=(6, 5, 3, 5),v=[0.03159551 0.17961941]\n",
      "k=(6, 6, 3, 5),v=[0.17208052 0.04170343]\n",
      "k=(6, 6, 3, 4),v=[0.02079885 0.10106521]\n",
      "k=(6, 6, 3, 3),v=[0.010199 0.      ]\n",
      "k=(6, 7, 0, 3),v=[0. 0.]\n",
      "k=(5, 6, 3, 5),v=[0.         0.02312988]\n",
      "k=(6, 6, 2, 3),v=[0.02144915 0.        ]\n",
      "k=(5, 5, 0, 3),v=[0. 0.]\n",
      "k=(5, 7, 5, 4),v=[0.01030103 0.09220178]\n",
      "k=(6, 7, 3, 3),v=[0.18557169 0.04159057]\n",
      "k=(6, 7, 1, 4),v=[0.05061358 0.019999  ]\n",
      "k=(6, 7, 0, 4),v=[0. 0.]\n",
      "k=(6, 7, 5, 4),v=[0.02040101 0.0511785 ]\n",
      "k=(6, 7, 3, 4),v=[0.         0.11424623]\n",
      "k=(4, 4, 4, 5),v=[0.08911092 0.01069705]\n",
      "k=(4, 3, 6, 7),v=[0.02 0.  ]\n",
      "k=(4, 3, 7, 7),v=[0.0201   0.010101]\n",
      "k=(4, 2, 7, 7),v=[0.0101 0.    ]\n",
      "k=(5, 8, 0, 2),v=[0. 0.]\n",
      "k=(5, 5, 3, 6),v=[0.03505321 0.62681365]\n",
      "k=(5, 6, 10, 6),v=[0. 0.]\n",
      "k=(6, 6, 6, 5),v=[0.2544976  0.04298208]\n",
      "k=(6, 6, 5, 4),v=[0.   0.01]\n",
      "k=(6, 7, 4, 4),v=[0.03130452 0.10926982]\n",
      "k=(6, 7, 2, 4),v=[0.03000783 0.12665355]\n",
      "k=(5, 4, 4, 7),v=[0.0101 0.    ]\n",
      "k=(6, 6, 8, 4),v=[0.02176466 0.        ]\n",
      "k=(6, 5, 10, 7),v=[0. 0.]\n",
      "k=(5, 3, 3, 7),v=[0.03990496 0.        ]\n",
      "k=(5, 3, 4, 7),v=[0.020298 0.020199]\n",
      "k=(6, 6, 5, 5),v=[0.1085208  0.01059895]\n",
      "k=(5, 6, 8, 6),v=[0.20591543 0.        ]\n",
      "k=(6, 7, 6, 3),v=[0.         0.05107955]\n",
      "k=(6, 8, 5, 3),v=[0.04255791 0.        ]\n",
      "k=(5, 5, 8, 7),v=[0.01936233 0.        ]\n",
      "k=(5, 6, 7, 6),v=[0.15181164 0.03023248]\n",
      "k=(5, 7, 8, 3),v=[0.        0.0103665]\n",
      "k=(5, 7, 3, 4),v=[0.         0.02154612]\n",
      "k=(6, 6, 6, 6),v=[0.09455857 0.02204678]\n",
      "k=(5, 7, 4, 4),v=[0.30239054 0.0108761 ]\n",
      "k=(4, 2, 10, 9),v=[0. 0.]\n",
      "k=(5, 4, 2, 4),v=[0.         0.03314993]\n",
      "k=(5, 4, 1, 4),v=[0.01 0.  ]\n",
      "k=(4, 4, 1, 5),v=[0.0199 0.    ]\n",
      "k=(4, 4, 0, 5),v=[0. 0.]\n",
      "k=(5, 8, 5, 3),v=[0.01069312 0.        ]\n",
      "k=(6, 6, 5, 6),v=[0.01029902 0.02117717]\n",
      "k=(5, 4, 0, 5),v=[0. 0.]\n",
      "k=(6, 7, 8, 5),v=[0.19957214 0.03131077]\n",
      "k=(7, 7, 7, 5),v=[0.   0.01]\n",
      "k=(7, 7, 7, 4),v=[0.0101 0.0199]\n",
      "k=(7, 7, 6, 4),v=[0.01 0.  ]\n",
      "k=(7, 7, 6, 5),v=[0.059302   0.03088509]\n",
      "k=(7, 6, 6, 6),v=[0.       0.010298]\n",
      "k=(8, 7, 6, 5),v=[0.0101 0.0199]\n",
      "k=(8, 7, 7, 5),v=[0.06058554 0.06941446]\n",
      "k=(9, 7, 7, 5),v=[0.01 0.  ]\n",
      "k=(9, 7, 7, 6),v=[0.0199 0.    ]\n",
      "k=(9, 6, 8, 6),v=[0.01 0.  ]\n",
      "k=(9, 6, 8, 7),v=[0.01 0.  ]\n",
      "k=(9, 6, 9, 7),v=[0.01 0.  ]\n",
      "k=(9, 6, 10, 7),v=[0. 0.]\n",
      "k=(6, 4, 10, 8),v=[0. 0.]\n",
      "k=(7, 6, 10, 6),v=[0. 0.]\n",
      "k=(6, 7, 7, 5),v=[0.0378942 0.       ]\n",
      "k=(6, 6, 6, 4),v=[0.03388191 0.        ]\n",
      "k=(5, 6, 6, 6),v=[0.08129675 0.        ]\n",
      "k=(6, 6, 7, 4),v=[0.         0.02167556]\n",
      "k=(6, 8, 3, 3),v=[0.   0.01]\n",
      "k=(7, 8, 3, 3),v=[0.   0.01]\n",
      "k=(7, 8, 2, 3),v=[0.   0.01]\n",
      "k=(7, 8, 1, 2),v=[0.   0.01]\n",
      "k=(7, 8, 0, 2),v=[0. 0.]\n",
      "k=(4, 5, 5, 4),v=[0.02147558 0.        ]\n",
      "k=(4, 5, 4, 4),v=[0.0101 0.0199]\n",
      "k=(4, 5, 3, 4),v=[0.01 0.01]\n",
      "k=(4, 5, 2, 4),v=[0.   0.01]\n",
      "k=(4, 5, 2, 3),v=[0.   0.01]\n",
      "k=(4, 5, 1, 3),v=[0.     0.0101]\n",
      "k=(4, 6, 0, 2),v=[0. 0.]\n",
      "k=(6, 8, 1, 3),v=[0.   0.01]\n",
      "k=0,v=[0. 0.]\n"
     ]
    }
   ],
   "source": [
    "for k,v in QVal.items():\n",
    "    print('k={},v={}'.format(k,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the estimated optimal policy\n",
    "QPolicy={}\n",
    "for k,v in QVal.items():\n",
    "    QPolicy[k] = [0] * num_actions\n",
    "    QPolicy[k][np.argmax(QVal[k])] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Points to Ponder\n",
    "1. Like our earlier lab we can decay $\\epsilon$ in different ways\n",
    "2. Even after 30,000 episodes it doesn't solve the environment.\n",
    "    * There is opportunity for tweaking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test our policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 finished after 24 steps with a Total Reward = 24\n",
      "Episode 2 finished after 17 steps with a Total Reward = 17\n"
     ]
    }
   ],
   "source": [
    "for i_episode in range(2): \n",
    "    state = env.reset()\n",
    "    tot_reward = 0\n",
    "    steps = 0\n",
    "    while True:\n",
    "        if getState(state) in QPolicy:\n",
    "            probs = QPolicy[getState(state)]\n",
    "        else:\n",
    "            print(\".\")\n",
    "            probs = [1.0/num_actions] * num_actions\n",
    "        action = np.random.choice(np.arange(num_actions), p=probs)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        # print('[',state,']',' -> ', action,' = [',next_state,']', reward)\n",
    "        tot_reward += reward\n",
    "        steps += 1\n",
    "        if done:\n",
    "            print('Episode {:d} finished after {:d} steps with a Total Reward = {:.0f}'.format(i_episode+1,steps, tot_reward))\n",
    "            break\n",
    "        else:\n",
    "            state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
