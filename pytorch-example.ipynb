{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A detour â€“ to DL machinery with pytorch\n",
    "\n",
    "## Goal:\n",
    "* Get familiar with a basic pytorch neural network\n",
    "\n",
    "## Steps:\n",
    "1. Define Network, loss & optimizer\n",
    "2. Get Dataset - MNIST\n",
    "3. Construct minibatch dataloader\n",
    "4. Forward pass\n",
    "5. Calculate error/loss\n",
    "6. Do backprop\n",
    "7. Update weights using Gradient Descent\n",
    "8. Train & Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference : \n",
    "* pytorch Udacity git https://github.com/udacity/deep-learning-v2-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Install the required packages\n",
    "\n",
    "* No esoteric requirements\n",
    "* You can run them without docker\n",
    "* pip install -r requirements.txt\n",
    "* Requirements\n",
    " * python 3.6, pytorch, openAI gym, numpy, matplotlib\n",
    " * anaconda is easier but not needed\n",
    " * Miniconda works fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define imports\n",
    "\n",
    "python 3, numpy, matplotlib, torch, gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import gym\n",
    "import PIL # for in-line display of certain environments\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import namedtuple, deque, defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# torch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Global Constants and other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants Definitions\n",
    "BUFFER_SIZE = 512 # int(1e5)  # replay buffer size\n",
    "BATCH_SIZE = 64         # minibatch size\n",
    "GAMMA = 0.99            # discount factor\n",
    "TAU = 1e-3              # for soft update of target parameters\n",
    "LR = 5e-4               # learning rate \n",
    "UPDATE_EVERY = 4        # how often to update the network\n",
    "# Number of neurons in the layers of the Network\n",
    "FC1_UNITS = 128\n",
    "FC2_UNITS = 64\n",
    "FC3_UNITS = 32\n",
    "# Store models flag. Store during calibration runs and do not store during hyperparameter search\n",
    "STORE_MODELS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. pytorch DL machinery "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size, seed=42, fc1_units = FC1_UNITS, fc2_units = FC2_UNITS, \n",
    "                 fc3_units = FC3_UNITS):\n",
    "        \"\"\"Initialize parameters and build model.\"\"\"\n",
    "        super(ANetwork, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fc1 = nn.Linear(input_size,fc1_units)\n",
    "        self.fc2 = nn.Linear(fc1_units,fc2_units)\n",
    "        # self.fc3 = nn.Linear(fc2_units,fc3_units)\n",
    "        # self.fc4 = nn.Linear(fc3_units,action_size)\n",
    "        self.fc4 = nn.Linear(fc2_units,output_size)\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"Build a network that maps state -> action values.\"\"\"\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # x = F.relu(self.fc3(x))\n",
    "        x = F.softmax(self.fc4(x),dim=-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Get MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                              ])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Construct minibatch dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Create network instance & loss \n",
    "### And a quick functional test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ANetwork(784,10)\n",
    "# Define the loss\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ANetwork(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get our data\n",
    "images, labels = next(iter(trainloader))\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logits = model(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Calculate error/loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3000, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the loss with the logits and the labels\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Do backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[-1.9411e-04, -1.9411e-04, -1.9411e-04,  ..., -1.9411e-04,\n",
      "         -1.9411e-04, -1.9411e-04],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 3.1654e-04,  3.1654e-04,  3.1654e-04,  ...,  3.1654e-04,\n",
      "          3.1654e-04,  3.1654e-04],\n",
      "        ...,\n",
      "        [ 1.4630e-04,  1.4630e-04,  1.4630e-04,  ...,  1.4630e-04,\n",
      "          1.4630e-04,  1.4630e-04],\n",
      "        [-8.2381e-05, -8.2381e-05, -8.2381e-05,  ..., -8.2381e-05,\n",
      "         -8.2381e-05, -8.2381e-05],\n",
      "        [ 2.4894e-04,  2.4894e-04,  2.4894e-04,  ...,  2.4894e-04,\n",
      "          2.4894e-04,  2.4894e-04]])\n"
     ]
    }
   ],
   "source": [
    "print('Before backward pass: \\n', model.fc1.weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('After backward pass: \\n', model.fc1.weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "# Optimizers require the parameters to optimize and a learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Update weights using Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weights -  Parameter containing:\n",
      "tensor([[ 0.0273,  0.0296, -0.0084,  ..., -0.0142,  0.0093,  0.0135],\n",
      "        [-0.0188, -0.0354,  0.0187,  ..., -0.0106, -0.0001,  0.0115],\n",
      "        [-0.0008,  0.0017,  0.0045,  ..., -0.0127, -0.0188,  0.0058],\n",
      "        ...,\n",
      "        [-0.0195,  0.0034,  0.0302,  ..., -0.0030, -0.0317,  0.0128],\n",
      "        [-0.0107,  0.0221, -0.0158,  ..., -0.0121,  0.0042,  0.0318],\n",
      "        [-0.0106,  0.0342,  0.0240,  ...,  0.0091,  0.0174,  0.0041]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Take an update step and few the new weights\n",
    "optimizer.step()\n",
    "print('Updated weights - ', model.fc1.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "### Now let us do full training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9054298902879645\n",
      "Training loss: 0.8417148233603821\n",
      "Training loss: 0.5145313322925364\n",
      "Training loss: 0.42803383418428365\n",
      "Training loss: 0.3852721249370941\n",
      "Elapsed : 0:00:40.669939\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# This is another way (probably easier) of building a network in pytorch\n",
    "# Instead of softmax, it uses log softmax\n",
    "\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # Training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    print(f\"Training loss: {running_loss/len(trainloader)}\")\n",
    "print('Elapsed : {}'.format(timedelta(seconds=time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Test\n",
    "#### I like the Udacity helper class - very good to test the MNIST results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import helper\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "ps = torch.exp(logps)\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Accuracy\n",
    "#### For this we need to load the test dataset, run the forward pass and then calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and load the test data\n",
    "testset = datasets.MNIST('MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(testloader))\n",
    "print(images.shape,labels.shape)\n",
    "\n",
    "img = images = images.view(images.shape[0], -1)\n",
    "# Get the class probabilities\n",
    "ps = torch.exp(model(img))\n",
    "# Make sure the shape is appropriate, we should get 10 class probabilities for 64 examples\n",
    "print(ps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "top_p, top_class = ps.topk(1, dim=1)\n",
    "print(top_class.shape)\n",
    "print(top_p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "equals = top_class == labels.view(*top_class.shape) # pay attention to shapes and sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.9375%\n"
     ]
    }
   ],
   "source": [
    "accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "print(f'Accuracy: {accuracy.item()*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _That's all Folks !_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
